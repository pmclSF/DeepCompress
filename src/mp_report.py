import json
import os

def generate_report(experiment_results, output_file):
    """
    Generate a detailed report from the experiment results.

    Args:
        experiment_results (dict): Dictionary containing the results of the experiment.
        output_file (str): Path to save the generated report.

    Returns:
        None
    """
    report = {}

    # Add experiment metadata (parameters, timestamp, etc.)
    report['experiment_metadata'] = {
        "octree_levels": experiment_results.get('octree_levels', 'N/A'),
        "quantization_levels": experiment_results.get('quantization_levels', 'N/A'),
        "num_files": len(experiment_results),
        "timestamp": experiment_results.get('timestamp', 'N/A')
    }

    # Track model performance
    model_performance = []
    best_overall = {
        'psnr': float('-inf'),
        'bd_rate': float('inf'),
        'bitrate': float('inf'),
        'compression_ratio': float('inf'),
        'compression_time': float('inf'),
        'decompression_time': float('inf')
    }

    best_per_model = {}

    for file, results in experiment_results.items():
        if file == 'timestamp' or file == 'octree_levels' or file == 'quantization_levels':
            continue  # Skip metadata entries
        
        # Collect model performance data
        model_data = {
            "file": file,
            "psnr": results.get('psnr', None),
            "bd_rate": results.get('bd_rate', None),
            "bitrate": results.get('bitrate', None),
            "compression_ratio": results.get('compression_ratio', None),
            "compression_time": results.get('compression_time', None),
            "decompression_time": results.get('decompression_time', None)
        }
        model_performance.append(model_data)

        # Track best performance across all metrics
        if results.get('psnr', float('-inf')) > best_overall['psnr']:
            best_overall['psnr'] = results.get('psnr')
            best_per_model['psnr'] = file
        if results.get('bd_rate', float('inf')) < best_overall['bd_rate']:
            best_overall['bd_rate'] = results.get('bd_rate')
            best_per_model['bd_rate'] = file
        if results.get('bitrate', float('inf')) < best_overall['bitrate']:
            best_overall['bitrate'] = results.get('bitrate')
            best_per_model['bitrate'] = file
        if results.get('compression_ratio', float('inf')) < best_overall['compression_ratio']:
            best_overall['compression_ratio'] = results.get('compression_ratio')
            best_per_model['compression_ratio'] = file
        if results.get('compression_time', float('inf')) < best_overall['compression_time']:
            best_overall['compression_time'] = results.get('compression_time')
            best_per_model['compression_time'] = file
        if results.get('decompression_time', float('inf')) < best_overall['decompression_time']:
            best_overall['decompression_time'] = results.get('decompression_time')
            best_per_model['decompression_time'] = file

    report['model_performance'] = model_performance

    # Add the overall best performance across all metrics
    report['best_performance'] = {
        "best_psnr": best_per_model['psnr'],
        "best_bd_rate": best_per_model['bd_rate'],
        "best_bitrate": best_per_model['bitrate'],
        "best_compression_ratio": best_per_model['compression_ratio'],
        "best_compression_time": best_per_model['compression_time'],
        "best_decompression_time": best_per_model['decompression_time']
    }

    # Compute aggregate statistics (best model, average performance, etc.)
    avg_psnr = sum([res['psnr'] for res in model_performance if res['psnr'] is not None]) / len(model_performance)
    avg_bd_rate = sum([res['bd_rate'] for res in model_performance if res['bd_rate'] is not None]) / len(model_performance)

    report['aggregate_statistics'] = {
        "avg_psnr": avg_psnr,
        "avg_bd_rate": avg_bd_rate
    }

    # Save the report to a file
    with open(output_file, 'w') as f:
        json.dump(report, f, indent=4)

    print(f"Report saved to {output_file}")

def load_experiment_results(input_file):
    """
    Load the experiment results from a JSON file.

    Args:
        input_file (str): Path to the JSON file containing experiment results.

    Returns:
        dict: Experiment results as a dictionary.
    """
    with open(input_file, 'r') as f:
        return json.load(f)

def main():
    # Example usage (assuming the experiment results are saved in a JSON file)
    input_file = 'experiment_results.json'  # This file would be generated by mp_run.py
    output_file = 'experiment_report.json'  # This will be the generated report
    
    # Load the experiment results from a JSON file
    experiment_results = load_experiment_results(input_file)
    
    # Generate the detailed report
    generate_report(experiment_results, output_file)

if __name__ == "__main__":
    main()
